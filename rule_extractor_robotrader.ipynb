{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe2d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías de manejo de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Configuración de pandas para mejor visualización\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.7f' % x)\n",
    "\n",
    "# Librerías de análisis técnico y estadística\n",
    "import talib as ta\n",
    "from scipy.stats import pointbiserialr\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# Librerías de paralelización y optimización\n",
    "import joblib\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import cupy as cp\n",
    "\n",
    "# Manejo de fechas y tiempo\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Librerías de bases de datos y almacenamiento\n",
    "import os\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "# Utilidades varias\n",
    "import uuid\n",
    "import itertools\n",
    "import re\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35f3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_df(csv_name, exposicion_dias=3, threshold=25, date_column='DateTime', short=False):\n",
    "    df = pd.read_csv(csv_name+'.csv')\n",
    "\n",
    "    def rsi_function(i):\n",
    "        rsi = ta.RSI(df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(rsi, columns=[f'rsi_{i}'])\n",
    "\n",
    "    rsi_dfs = pd.concat([rsi_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, rsi_dfs], axis=1)\n",
    "\n",
    "    def adx_function(i):\n",
    "        adx = ta.ADX(df['High'], df['Low'], df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(adx, columns=[f'adx_{i}'])\n",
    "\n",
    "    adx_dfs = pd.concat([adx_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, adx_dfs], axis=1)\n",
    "\n",
    "    def plus_di_function(i):\n",
    "        plus_di = ta.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(plus_di, columns=[f'plus_di_{i}'])\n",
    "\n",
    "    plus_di_dfs = pd.concat([plus_di_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, plus_di_dfs], axis=1)\n",
    "\n",
    "    def minus_di_function(i):\n",
    "        minus_di = ta.MINUS_DI(df['High'], df['Low'], df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(minus_di, columns=[f'minus_di_{i}'])\n",
    "\n",
    "    minus_di_dfs = pd.concat([minus_di_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, minus_di_dfs], axis=1)\n",
    "\n",
    "    def willr_function(i):\n",
    "        willr = ta.WILLR(df['High'], df['Low'], df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(willr, columns=[f'willr_{i}'])\n",
    "\n",
    "    willr_dfs = pd.concat([willr_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, willr_dfs], axis=1)\n",
    "\n",
    "    def ma_function(i):\n",
    "        ma = ta.MA(df['Close'], timeperiod=i, matype=0)\n",
    "        return pd.DataFrame(ma, columns=[f'sma_{i}'])\n",
    "\n",
    "    ma_dfs = pd.concat([ma_function(i) for i in range(2, 301, 2)], axis=1)\n",
    "    df = pd.concat([df, ma_dfs], axis=1)\n",
    "\n",
    "    def ema_function(i):\n",
    "        ma = ta.EMA(df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(ma, columns=[f'mema_{i}'])\n",
    "\n",
    "    ema_dfs = pd.concat([ema_function(i) for i in range(2, 301, 2)], axis=1)\n",
    "    df = pd.concat([df, ema_dfs], axis=1)\n",
    "\n",
    "    def atr_function(i):\n",
    "        atr = ta.ATR(df['High'], df['Low'], df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(atr, columns=[f'atr_{i}'])\n",
    "\n",
    "    atr_dfs = pd.concat([atr_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, atr_dfs], axis=1)\n",
    "\n",
    "    def calculate_ibs(high, low, close):\n",
    "        ibs = (close - low) / (high - low)\n",
    "        ibs = np.round(ibs, 2)\n",
    "        return pd.DataFrame(ibs, columns=['ibs_'])\n",
    "\n",
    "\n",
    "    def stdev_function(i):\n",
    "            stdev = ta.STDDEV(df['Close'], timeperiod=i, nbdev=1)\n",
    "            return pd.DataFrame(stdev, columns=[f'stdev_{i}'])\n",
    "        \n",
    "    stdev_dfs = pd.concat([stdev_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, stdev_dfs], axis=1)\n",
    "\n",
    "    def bband_function(i, dev=2):\n",
    "        upperband, middleband, lowerband = ta.BBANDS(df['Close'], timeperiod=i, nbdevup=dev, nbdevdn=dev, matype=0)\n",
    "        return pd.DataFrame({f'bb_upper_{dev}_{i}': upperband, f'bb_middle_{dev}_{i}': middleband, f'bb_lower_{dev}_{i}': lowerband})\n",
    "    \n",
    "    def bband_function(i, dev=2):\n",
    "        upperband, middleband, lowerband = ta.BBANDS(df['Close'], timeperiod=i, nbdevup=dev, nbdevdn=dev, matype=0)\n",
    "        return pd.DataFrame({f'bb_upper_{dev}_{i}': upperband, f'bb_lower_{dev}_{i}': lowerband})\n",
    "\t\n",
    "    for dev in range(2,6):\n",
    "        bband_dfs = pd.concat([bband_function(i, dev) for i in range(5, 31, 2)], axis=1)\n",
    "        df = pd.concat([df, bband_dfs], axis=1)\n",
    "        \n",
    "\n",
    "    def macd_function(fp, slp, sp):\n",
    "        macd, macdsignal, macdhist = ta.MACD(df['Close'], fastperiod=fp, slowperiod=slp, signalperiod=sp)\n",
    "        return pd.DataFrame({f'macd_{fp}': macd, f'macdsig_{slp}': macdsignal, f'macdh_{sp}': macdhist})\n",
    "\n",
    "    macd_dfs = []\n",
    "    fastperiod_values = [7, 12, 26, 52]\n",
    "    slowperiod_values = [13, 26, 52]\n",
    "    signalperiod_values = [3, 6, 9]\n",
    "\n",
    "\n",
    "    def mom_function(i):\n",
    "        momentum = ta.MOM(df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(momentum, columns=[f'mom_{i}'])\n",
    "\n",
    "    momentum_dfs = pd.concat([mom_function(i) for i in range(2, 31, 2)], axis=1)\n",
    "    df = pd.concat([df, momentum_dfs], axis=1)\n",
    "\n",
    "    def aaron_up_function(i):\n",
    "        aroon_up = ta.AROONOSC(df['High'], df['Low'], timeperiod=i)\n",
    "        return pd.DataFrame(aroon_up, columns=[f'aaro_{i}'])\n",
    "\n",
    "    aaronu_dfs = pd.concat([aaron_up_function(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, aaronu_dfs], axis=1)\n",
    "\t\n",
    "    def aaron_up_function2(i):\n",
    "        _, aroon_up = ta.AROON(df['High'], df['Low'], timeperiod=i)\n",
    "        return pd.DataFrame(aroon_up, columns=[f'aarou_{i}'])\n",
    "\t\n",
    "    aaronu_dfs = pd.concat([aaron_up_function2(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, aaronu_dfs], axis=1)\n",
    "\t\n",
    "    def aaron_dw_function2(i):\n",
    "        aroon_down, _ = ta.AROON(df['High'], df['Low'], timeperiod=i)\n",
    "        return pd.DataFrame(aroon_down, columns=[f'aarod_{i}'])\n",
    "\t\n",
    "    aaronu_dfs = pd.concat([aaron_dw_function2(i) for i in range(2, 51, 2)], axis=1)\n",
    "    df = pd.concat([df, aaronu_dfs], axis=1)\n",
    "\n",
    "    def roc_function(i):\n",
    "        roc_t = ta.ROC(df['Close'], timeperiod=i)\n",
    "        return pd.DataFrame(roc_t, columns=[f'roc_{i}'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    duplicates = df.columns[df.columns.duplicated()]\n",
    "    df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "    def shift_column(column, i):\n",
    "        shifted = df[column].shift(i)\n",
    "        if('ibs_' in column):\n",
    "            column = 'ibs'\n",
    "        return shifted.rename(f'{column}_sft_{i}')\n",
    "\n",
    "    columns = df.columns\n",
    "    lista_shift = ['rsi', 'adx', 'plus_di', 'minus_di', 'willr', 'bb', 'atr', 'stdev', 'Close', 'High', 'Low', 'aaro', 'mom']\n",
    "    indicator_columns = {col for col in columns if any(name in col for name in lista_shift)}\n",
    "\n",
    "    shifted_columns = []\n",
    "    shift_value = 3\n",
    "\n",
    "    for column in indicator_columns:\n",
    "        for i in range(1, shift_value + 1):\n",
    "            shifted_series = shift_column(column, i)\n",
    "            shifted_columns.append(shifted_series)\n",
    "\n",
    "    df = pd.concat([df] + shifted_columns, axis=1)\n",
    "\n",
    "\n",
    "    pips = 0\n",
    "    if \"JPY\" in csv_name:\n",
    "        pips = 100\n",
    "    else:\n",
    "        pips = 10000\n",
    "\n",
    "\n",
    "    for i in range (2,31, 2):\n",
    "        ret = []\n",
    "        new_cols = []\n",
    "        if(short == True):\n",
    "            ret = ((df[\"Close\"].shift(-1 * i) - df[\"Close\"]) * pips) + 2\n",
    "            new_cols = pd.DataFrame(np.array(ret) * -1, columns=[f\"Return_{i}\"])\n",
    "        else:\n",
    "            ret = ((df[\"Close\"].shift(-1 * i) - df[\"Close\"]) * pips) - 2\n",
    "            new_cols = pd.DataFrame(np.array(ret), columns=[f\"Return_{i}\"])\n",
    "\t\t\t\n",
    "        df = pd.concat([df, new_cols], axis=1)\n",
    "\n",
    "\n",
    "    if(short == True):\n",
    "        ret = ((df[\"Close\"].shift(-1 * exposicion_dias) - df[\"Close\"]) * pips) + 2\n",
    "    else:\n",
    "        ret = ((df[\"Close\"].shift(-1 * exposicion_dias) - df[\"Close\"]) * pips) - 2\n",
    "\t\t\n",
    "    new_cols = pd.DataFrame(np.array(ret), columns=[\"Return\"])\n",
    "\t\n",
    "    if(short == True):\n",
    "        new_cols[\"Return\"] = new_cols[\"Return\"] * -1\n",
    "\t\t\n",
    "    df = pd.concat([df, new_cols], axis=1)\n",
    "    \n",
    "    target = (df[\"Return\"] >= threshold).astype(int)\n",
    "\t\n",
    "\n",
    "    target = df[f'Return_{exposicion_dias}'].copy()\n",
    "    target = (df[f'Return_{exposicion_dias}'] >= threshold).astype(int)\n",
    "    df = pd.concat([df, target.rename(\"Target\")], axis=1) \n",
    "\n",
    "    for i in range (4,31, 2):\n",
    "        target = (df[f'Return_{i}'] >= threshold).astype(int)\n",
    "        df = pd.concat([df, target.rename(f'Target_{i}')], axis=1) \n",
    "\t\n",
    "    \n",
    "\n",
    "    df = df.copy()\n",
    "    df[date_column] = pd.to_datetime(df[date_column], dayfirst=True)\n",
    "\n",
    "    day_of_month = df[date_column].apply(lambda x: x.day)\n",
    "    month = df[date_column].apply(lambda x: x.month)\n",
    "    day_of_week = df[date_column].apply(lambda x: x.weekday())\n",
    "    year = df[date_column].apply(lambda x: x.year)\n",
    "\n",
    "    df[date_column] = df[date_column].dt.strftime('%d/%m/%Y %H:%M')\n",
    "\n",
    "    new_columns = pd.concat([day_of_month.rename('day_of_month'), month.rename('month'), day_of_week.rename('day_of_week'), year.rename('year')], axis=1)\n",
    "    df = pd.concat([df, new_columns], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def split_data_validation(df, year_max_cut = '2022', year_min_cur= '2008'):\n",
    "    data = df.query('year >= ' + year_max_cut).copy()\n",
    "    df = df.query(year_min_cur+' < year <= 2022')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df, data\n",
    "\n",
    "def map_creator(df):\n",
    "    inicio = time.time()\n",
    "    columns = df.columns\n",
    "    no_sft_columns = [col for col in columns if 'sft' not in col]\n",
    "    column_map = create_column_map(df, columns, no_sft_columns)\n",
    "    fin = time.time()\n",
    "    duracion = fin - inicio\n",
    "    print(\"La duración del proceso fue de\", duracion, \"segundos\")\n",
    "    return column_map\n",
    "\n",
    "def create_column_map(df, columns, no_sft_columns):\n",
    "    column_map = {}\n",
    "    rsi_columns = {col for col in columns if 'rsi_' in col}\n",
    "    adx_columns = {col for col in columns if 'adx' in col}\n",
    "    plus_di_columns = {col for col in columns if 'plus_di' in col}\n",
    "    minus_di_columns = {col for col in columns if 'minus_di' in col}\n",
    "    will_columns = {col for col in columns if 'willr' in col}\n",
    "    sma_columns = {col for col in columns if 'sma' in col}\n",
    "    mema_columns = {col for col in columns if 'mema' in col}\n",
    "    ibs_columns = {col for col in columns if 'ibs_' in col}\n",
    "    atr_columns = {col for col in columns if 'atr' in col}\n",
    "    bbup_columns = {col for col in columns if 'bb_upper' in col}\n",
    "    bbmid_columns = {col for col in columns if 'bb_middle' in col}\n",
    "    bblow_columns = {col for col in columns if 'bb_lower' in col}\n",
    "    macd_columns = {col for col in columns if 'macd' in col}\n",
    "    macdsig_columns = {col for col in columns if 'macdsig' in col}\n",
    "    macdh_columns = {col for col in columns if 'macdh' in col}\n",
    "    ibsma_columns = {col for col in columns if 'ibma' in col}\n",
    "    hh_columns = {col for col in columns if 'hh' in col}\n",
    "    dayw_columns = {col for col in columns if 'day_of_week' in col}\n",
    "    daym_columns = {col for col in columns if 'day_of_month' in col}\n",
    "    ll_columns = {col for col in columns if 'll' in col}\n",
    "    mom_columns = {col for col in columns if 'mom' in col}\n",
    "    aaro_columns = {col for col in columns if 'aaro_' in col}\n",
    "    roc_columns = {col for col in columns if 'roc' in col}\n",
    "    stoch_columns = {col for col in columns if 'stoch' in col}\n",
    "    stochk_columns = {col for col in columns if 'stochk' in col}\n",
    "    stochd_columns = {col for col in columns if 'stochd' in col}\n",
    "    stdev_columns = {col for col in columns if 'stdev' in col}\n",
    "    aarod_columns = {col for col in columns if 'aarod_' in col}\n",
    "    aarou_columns = {col for col in columns if 'aarou_' in col}\n",
    "    \n",
    "    for column in no_sft_columns:\n",
    "        if 'rsi' in column:\n",
    "            filtered_columns = rsi_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col and 'ibs' not in col}\n",
    "            column_map[column] = [list(range(0, 101)), list(filtered_columns)]\n",
    "\n",
    "        elif 'adx' in column:\n",
    "            filtered_columns = adx_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(range(0, 101)), list(filtered_columns)]\n",
    "        \n",
    "        elif 'plus_di' in column:\n",
    "            filtered_columns = plus_di_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(range(0, 101)), list(filtered_columns)]\n",
    "                                                            \n",
    "        elif 'minus_di' in column:\n",
    "            filtered_columns = minus_di_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(range(0, 101)), list(filtered_columns)]\n",
    "            \n",
    "        elif 'willr' in column:\n",
    "            filtered_columns = will_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(x for x in range(0, -101, -1)), list(filtered_columns)]\n",
    "                                                            \n",
    "        elif 'sma' in column:\n",
    "            filtered_columns = sma_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(['Open', 'High', 'Low', 'Close', 'Close_sft_1', 'Close_sft_2', 'Close_sft_3', 'Low_sft_1', 'Low_sft_2', 'Low_sft_3', 'High_sft_1', 'High_sft_2', 'High_sft_3']), list(filtered_columns)]  \n",
    "\n",
    "        elif 'mema' in column:\n",
    "            filtered_columns = mema_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(['Open', 'High', 'Low', 'Close', 'Close_sft_1', 'Close_sft_2', 'Close_sft_3', 'Low_sft_1', 'Low_sft_2', 'Low_sft_3', 'High_sft_1', 'High_sft_2', 'High_sft_3']), list(filtered_columns)]\t\t\t\n",
    "            \n",
    "        elif 'ibs_' in column:\n",
    "            filtered_columns = ibs_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list([i / 100 for i in range(0, 101)]), list(filtered_columns)]\n",
    "        \n",
    "        elif 'atr' in column:\n",
    "            filtered_columns = atr_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_columns)]\n",
    "            \n",
    "        elif 'bb_upper' in column:\n",
    "            filtered_columns = bbup_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(['Open', 'High', 'Low', 'Close', 'Close_sft_1', 'Close_sft_2', 'Close_sft_3', 'Low_sft_1', 'Low_sft_2', 'Low_sft_3', 'High_sft_1', 'High_sft_2', 'High_sft_3']), list(filtered_columns)]\n",
    "        \n",
    "        elif 'bb_middle' in column:\n",
    "            filtered_columns = bbmid_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(['Open', 'High', 'Low', 'Close', 'Close_sft_1', 'Close_sft_2', 'Close_sft_3', 'Low_sft_1', 'Low_sft_2', 'Low_sft_3', 'High_sft_1', 'High_sft_2', 'High_sft_3']), list(filtered_columns)]\n",
    "            \n",
    "        elif 'bb_lower' in column:\n",
    "            filtered_columns = bblow_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(['Open', 'High', 'Low', 'Close', 'Close_sft_1', 'Close_sft_2', 'Close_sft_3', 'Low_sft_1', 'Low_sft_2', 'Low_sft_3', 'High_sft_1', 'High_sft_2', 'High_sft_3']), list(filtered_columns)]\n",
    "            \n",
    "        elif 'macd' in column:\n",
    "            filtered_columns = macd_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(macdsig_columns)]\n",
    "        \n",
    "        elif 'macdsig' in column:\n",
    "            filtered_columns = macdsig_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(macd_columns)]\n",
    "                                  \n",
    "        elif 'macdh' in column:\n",
    "            filtered_columns = macdh_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_columns)]\n",
    "        \n",
    "        elif 'ibma' in column:\n",
    "            filtered_columns = ibsma_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(ibs_columns)]\n",
    "        \n",
    "        elif 'hh' in column:\n",
    "            filtered_columns = hh_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(['Open', 'High', 'Low', 'Close', 'Close_sft_1', 'Close_sft_2', 'Close_sft_3', 'Low_sft_1', 'Low_sft_2', 'Low_sft_3', 'High_sft_1', 'High_sft_2', 'High_sft_3'])]\n",
    "            \n",
    "        elif 'day_of_week' in column:\n",
    "            filtered_columns = dayw_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list([i for i in range(0, 7)]), list([i for i in range(0, 7)])]\n",
    "        \n",
    "        elif 'day_of_week' in column:\n",
    "            filtered_columns = dayw_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list([i for i in range(0, 7)]), list([i for i in range(0, 7)])]\n",
    "        \n",
    "        elif 'day_of_month' in column:\n",
    "            filtered_columns = daym_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list([i for i in range(1, 32)]), list([i for i in range(1, 32)])]\n",
    "        \n",
    "        \n",
    "        elif 'mom' in column:\n",
    "            filtered_columns = mom_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_columns)]\n",
    "            \n",
    "        elif 'aaro_' in column:\n",
    "            filtered_columns = aaro_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(x for x in range(-100, 101, 1)), list(filtered_columns)]\n",
    "\t\t\t\n",
    "        elif 'aarod_' in column:\n",
    "            filtered_columns = aarod_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(x for x in range(0, 101)), list(filtered_columns)]\n",
    "\t\t\t\n",
    "        elif 'aarou_' in column:\n",
    "            filtered_columns = aarou_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(x for x in range(0, 101)), list(filtered_columns)]\n",
    "        \n",
    "        elif 'roc' in column:\n",
    "            filtered_columns = roc_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_columns)]\n",
    "        \n",
    "        elif 'stochd' in column:\n",
    "            filtered_columns = stochd_columns - {column}\n",
    "            comun_columns = stoch_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            filtered_comun_columns = {col for col in comun_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_comun_columns)]\n",
    "            \n",
    "        elif 'stochk' in column:\n",
    "            filtered_columns = stochk_columns - {column}\n",
    "            comun_columns = stoch_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            filtered_comun_columns = {col for col in comun_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_comun_columns)]\n",
    "        \n",
    "        elif 'stdev' in column:\n",
    "            filtered_columns = stdev_columns - {column}\n",
    "            filtered_columns = {col for col in filtered_columns if 'condition' not in col}\n",
    "            column_map[column] = [list(filtered_columns), list(filtered_columns)]\n",
    "            \n",
    "\n",
    "    return column_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ac9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_directorio(nombre_carpeta):\n",
    "    try:\n",
    "        os.makedirs(nombre_carpeta)\n",
    "        print(f\"Directorio '{nombre_carpeta}' creado con éxito.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"El directorio '{nombre_carpeta}' ya existe.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al crear el directorio '{nombre_carpeta}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad4de9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date_column = 'DateTime'\n",
    "h12 = 'GBPNZ_H12'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposicion_dias=4\n",
    "threshold=65\n",
    "df = transform_df(h12, exposicion_dias, threshold, short=True)\n",
    "dir_results_name = f'results_{exposicion_dias}_{threshold}'\n",
    "crear_directorio(dir_results_name)\n",
    "full_df = df.copy()\n",
    "df = df.query('2016 < year < 2019')\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "column_map = map_creator(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e25842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7b989",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50e9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_columns = [col for col in df.columns if 'Return_' in col]\n",
    "df[return_columns+['Return']].tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4a15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df[df['day_of_week'] == 6]))\n",
    "print(len(df[df['day_of_week'] == 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9044ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_rules(column_map, df):\n",
    "    all_rules = [] \n",
    "    \n",
    "    for column, (possible_values, related_columns) in column_map.items():\n",
    "        if 'day' in column:\n",
    "            operators = ['>', '<', '==', '>=', '<=']\n",
    "        else:\n",
    "            operators = ['>=', '<=']\n",
    "\n",
    "        for value in possible_values:\n",
    "            for operator in operators:\n",
    "                condition = f\"{column} {operator} {value}\"\n",
    "                all_rules.append(condition)\n",
    "\n",
    "        for value in related_columns:\n",
    "                for operator in operators:\n",
    "                    related_condition = f\"{column} {operator} {value}\"\n",
    "                    all_rules.append(related_condition)\n",
    "    \n",
    "    return all_rules\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules = generate_all_rules(column_map, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_hash(s):\n",
    "    try:\n",
    "        first_part = re.findall(r'^\\D+', s.split(' ')[0])[0]\n",
    "        comparison_operator = re.findall(r'[<=>=]+', s)[0]\n",
    "        try:\n",
    "            second_part = re.findall(r'^\\D+', s.split(' ')[2].split('_')[0])[0]\n",
    "        except IndexError:\n",
    "            second_part = 'num'\n",
    "        combined = first_part + comparison_operator + second_part\n",
    "        return hashlib.sha256(combined.encode()).hexdigest()\n",
    "    except Exception as e:\n",
    "        return 12345678910\n",
    "\n",
    "\n",
    "def process_rule_chunk(df, data, df_columns, rule_chunk, target_values, target, returns_columns):\n",
    "    chunk_results = {}\n",
    "    chunk_stats = {}\n",
    "    for rule in rule_chunk:\n",
    "        try:\n",
    "            parts = rule.split()\n",
    "            if len(parts) == 3:\n",
    "                column1, operator, column2_or_value = parts\n",
    "                idx1 = df_columns.get_loc(column1)\n",
    "                idx_return = df_columns.get_loc('Return')\n",
    "                \n",
    "                try:\n",
    "                    value = float(column2_or_value)\n",
    "                    idx2 = None\n",
    "                except ValueError:\n",
    "                    idx2 = df_columns.get_loc(column2_or_value)\n",
    "                    \n",
    "                condition_eval_df = None\n",
    "                if operator == '>=':\n",
    "                    if idx2 is None:\n",
    "                        condition_eval_df = (data[:, idx1] >= value)\n",
    "                    else:\n",
    "                        condition_eval_df = (data[:, idx1] >= data[:, idx2])\n",
    "                elif operator == '<=':\n",
    "                    if idx2 is None:\n",
    "                        condition_eval_df = (data[:, idx1] <= value)\n",
    "                    else:\n",
    "                        condition_eval_df = (data[:, idx1] <= data[:, idx2])\n",
    "                elif operator == '==':\n",
    "                    if idx2 is None:\n",
    "                        condition_eval_df = (data[:, idx1] == value)\n",
    "                    else:\n",
    "                        condition_eval_df = (data[:, idx1] == data[:, idx2])\n",
    "                        \n",
    "                condition_eval = condition_eval_df.astype(np.int8)\n",
    "                ones_count = np.sum(condition_eval)\n",
    "                if ones_count < 100:\n",
    "                    continue\n",
    "                \n",
    "                correlation, _ = pointbiserialr(condition_eval, target)\n",
    "                if np.isnan(correlation):\n",
    "                    continue\n",
    "\n",
    "                length = len(condition_eval)\n",
    "                zeros_count = length - ones_count\n",
    "                win_rate = np.sum(condition_eval & target_values) / ones_count if ones_count > 0 else 0\n",
    "\n",
    "                \n",
    "                sum_returns = np.sum(data[condition_eval_df, idx_return])\n",
    "                \n",
    "                sum_positive_returns = np.sum(data[condition_eval_df & (data[:, idx_return] > 0), idx_return])\n",
    "                sum_negative_returns = np.sum(data[condition_eval_df & (data[:, idx_return] < 0), idx_return])\n",
    "                \n",
    "                profit_factor = 0\n",
    "                if sum_negative_returns != 0:\n",
    "                    profit_factor = sum_positive_returns / -sum_negative_returns\n",
    "                else:\n",
    "                    profit_factor = float('inf')\n",
    "                    \n",
    "                optimal_pf = 0\n",
    "                optimal_exposition = str(4)\n",
    "                profit_factors = {}\n",
    "                for ret_col in returns_columns:\n",
    "                    idx_return = df_columns.get_loc(ret_col)\n",
    "                    sum_positive_returns = np.sum(data[condition_eval_df & (data[:, idx_return] > 0), idx_return])\n",
    "                    sum_negative_returns = -np.sum(data[condition_eval_df & (data[:, idx_return] < 0), idx_return])\n",
    "                    profit_factor = sum_positive_returns / sum_negative_returns if sum_negative_returns != 0 else float('inf')\n",
    "                    match = re.search(r'Return_(\\d+)', ret_col)\n",
    "                    number = 4\n",
    "                    if match:\n",
    "                        number = match.group(1)\n",
    "                        chunk_stats[f'pf_{str(number)}'] = profit_factor\n",
    "                        if(profit_factor != np.inf and profit_factor > optimal_pf):\n",
    "                            optimal_pf = profit_factor\n",
    "                            optimal_exposition = str(number)\n",
    "                        \n",
    "                target_optimal = df[f'Target_{optimal_exposition}'].values\n",
    "                target_values_optimal = df[f'Target_{optimal_exposition}'].apply(lambda x: 1 if x > 0 else 0).values\n",
    "                correlation_optimal, _ = pointbiserialr(condition_eval, target_optimal)\n",
    "                win_rate_optimal = np.sum(condition_eval & target_values_optimal) / ones_count if ones_count > 0 else 0\n",
    "                \n",
    "                \n",
    "                chunk_results[rule] = condition_eval\n",
    "                chunk_stats[rule] = {\n",
    "                    'correlation': correlation,\n",
    "                    'length': length,\n",
    "                    'ones_count': ones_count,\n",
    "                    'zeros_count': zeros_count,\n",
    "                    'win_rate': round(win_rate * 100, 2),\n",
    "                    'return': sum_returns,\n",
    "                    'hash': generate_hash(rule),\n",
    "                    'optimal_exposition': optimal_exposition,\n",
    "                    'correlation_optimal': correlation_optimal,\n",
    "                    'win_rate_optimal': round(win_rate_optimal * 100, 2),\n",
    "                }\n",
    "                chunk_stats[rule].update({f'pf_{i}': chunk_stats.pop(f'pf_{i}') for i in range(4, 31, 2)})\n",
    "                \n",
    "            else:\n",
    "                print(f\"Rule '{rule}' could not be parsed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing rule '{rule}': {e}\")\n",
    "\n",
    "    return chunk_results, chunk_stats\n",
    "\n",
    "\n",
    "def evaluate_rules_numpy(df, all_rules, target_column='Target', output_file='results2_h5.h5'):\n",
    "    print('Starting process..', datetime.now().strftime('%d-%m-%Y %H:%M:%S'))\n",
    "    data = df.to_numpy()\n",
    "    target = df[target_column].values\n",
    "    target_values = df[target_column].apply(lambda x: 1 if x > 0 else 0).values\n",
    "\n",
    "\n",
    "    num_cores = joblib.cpu_count()\n",
    "\n",
    "    # Dividimos las reglas en chunks\n",
    "    chunk_size = len(all_rules) // num_cores \n",
    "    rule_chunks = [all_rules[i:i + chunk_size] for i in range(0, len(all_rules), chunk_size)]\n",
    "    \n",
    "    returns_columns = [f'Return_{i}' for i in range(4, 31, 2)]  \n",
    "\n",
    "    # Utilizar Joblib para paralelizar la evaluación de las reglas\n",
    "    results = Parallel(n_jobs=-1)(\n",
    "        delayed(process_rule_chunk)(df, data, df.columns, rule_chunk, target_values, target, returns_columns) for rule_chunk in rule_chunks\n",
    "    )\n",
    "    \n",
    "    all_results = {}\n",
    "    all_stats = {}\n",
    "    for chunk_results, chunk_stats in results:\n",
    "        all_results.update(chunk_results)\n",
    "        all_stats.update(chunk_stats)\n",
    "        \n",
    "    result_df = pd.DataFrame(all_results)\n",
    "    result_df['Target'] = df['Target'].copy()\n",
    "    result_df['Return'] = df['Return'].copy()\n",
    "    \n",
    "    returns_columns = []\n",
    "    for i in range(4, 31, 2):\n",
    "        returns_columns.append(f'Return_{i}')\n",
    "        \n",
    "        \n",
    "    for column_ in returns_columns:\n",
    "        result_df[column_] = df[column_].values\n",
    "        \n",
    "    \n",
    "    print('Ending process.. saving', datetime.now().strftime('%d-%m-%Y %H:%M:%S'), len(result_df))\n",
    "    result_df.to_hdf(output_file, key='result_df', mode='w')\n",
    "    sorted_stats = sorted(all_stats.items(), key=lambda item: item[1]['correlation'], reverse=True)\n",
    "    \n",
    "    groups = groupby(sorted_stats, key=lambda item: item[1]['correlation'])\n",
    "    unique_stats = [next(g) for _, g in groups]\n",
    "    \n",
    "    df = pd.DataFrame([item[1] for item in unique_stats])\n",
    "    df['condition'] = [item[0] for item in unique_stats]\n",
    "    df = df[['condition'] + [col for col in df.columns if col != 'condition']]\n",
    "    \n",
    "    print('Ended process',datetime.now().strftime('%d-%m-%Y %H:%M:%S'))\n",
    "    return df, unique_stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f863b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_rules, sorted_stats = evaluate_rules_numpy(df, all_rules)\n",
    "\n",
    "print(f\"El proceso tardó {time.time() - start_time} segundos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89792e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total de backtests ejecutados: {len(df_rules) * 14}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d4859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_rules.sort_values(by='pf_10', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b346c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7e7a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
